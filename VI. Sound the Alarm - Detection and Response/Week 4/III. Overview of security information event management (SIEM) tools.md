# Reexamine SIEM tools

- **SIEM Overview:** **[[Security Information and Event Management (SIEM)]]**. It is an application used to collect, analyze, and report on log data from various sources within an organization. SIEM tools play a critical role in monitoring and managing security-related activities.
- **SIEM Data Collection Process:** SIEM tools go through a systematic data collection process that involves the following steps:
	1. **[[Data Collection and Processing]]:** SIEM tools collect and process vast amounts of data generated by devices and systems throughout an environment. This data comes in different formats.
	2. **[[Normalization]]:** SIEM tools normalize the data, ensuring that it is consistently formatted and includes only relevant event information. Normalization simplifies data analysis.
	3. **[[Indexing]]:** The normalized data is indexed, making it easily accessible through search. This indexing allows security analysts to quickly access and analyze events from various sources.
- **SIEM Flexibility:** As a security analyst, you may encounter different SIEM tools based on your organization's preferences. It's essential to be adaptable and proficient with the specific SIEM tool your organization utilizes.
- **SIEM Platforms:** Two examples of SIEM tools were introduced:
	1. **[[Splunk]]:** Splunk is a data analysis platform that offers SIEM solutions. It collects data from multiple sources, processes and stores it in an index, and provides various methods for accessing and searching the data.
	2. **[[Chronicle]]:** Chronicle is Google Cloud's SIEM, which receives security data, normalizes it for efficient processing, and makes it accessible through a search interface.
These SIEM tools play a pivotal role in the work of a security analyst by simplifying the process of collecting, analyzing, and accessing data from various sources. They empower security analysts to efficiently monitor systems, investigate incidents, and respond to potential security threats. In the next section, you'll delve into the practical aspect of using SIEM tools by learning how to search for and analyze security data on these platforms.

# Log sources and log ingestion

In this reading, you’ll explore more on the importance of log ingestion. You may recall that **[[security information and event management (SIEM)]]** tools collect and analyze log data to monitor critical activities in an organization. You also learned about **[[log analysis]],** which is the process of examining logs to identify events of interest. Understanding how log sources are ingested into SIEM tools is important because it helps security analysts understand the types of data that are being collected, and can help analysts identify and prioritize security incidents.

## SIEM process overview

Previously, you covered the SIEM process. As a refresher, the process consists of three steps:

1. **[[Collect and aggregate data]]**: SIEM tools collect event data from various data sources.
2. **[[Normalize data]]**: Event data that's been collected becomes normalized. Normalization converts data into a standard format so that data is structured in a consistent way and becomes easier to read and search. While data normalization is a common feature in many SIEM tools, it's important to note that SIEM tools vary in their data normalization capabilities.
3. **[[Analyze data]]**: After the data is collected and normalized, SIEM tools analyze and correlate the data to identify common patterns that indicate unusual activity.

This reading focuses on the first step of this process, the collection and aggregation of data.

## Log ingestion

![[Pasted image 20231107204219.png]]

Data is required for SIEM tools to work effectively. SIEM tools must first collect data using log ingestion. **[[Log ingestion]]** is the process of collecting and importing data from log sources into a SIEM tool. Data comes from any source that generates log data, like a server.

In log ingestion, the SIEM creates a copy of the event data it receives and retains it within its own storage. This copy allows the SIEM to analyze and process the data without directly modifying the original source logs. The collection of event data provides a centralized platform for security analysts to analyze the data and respond to incidents. This event data includes authentication attempts, network activity, and more.

### Log forwarders

There are many ways SIEM tools can ingest log data. For instance, you can manually upload data or use software to help collect data for log ingestion. Manually uploading data may be inefficient and time-consuming because networks can contain thousands of systems and devices. Hence, it's easier to use software that helps collect data. 

A common way that organizations collect log data is to use log forwarders. Log forwarders are software that automate the process of collecting and sending log data. Some operating systems have native log forwarders. If you are using an operating system that does not have a native log forwarder, you would need to install a third-party log forwarding software on a device. After installing it, you'd configure the software to specify which logs to forward and where to send them. For example, you can configure the logs to be sent to a SIEM tool. The SIEM tool would then process and normalize the data. This allows the data to be easily searched, explored, correlated, and analyzed.

**Note**: Many SIEM tools utilize their own proprietary log forwarders. SIEM tools can also integrate with open-source log forwarders. Choosing the right log forwarder depends on many factors such as the specific requirements of your system or organization, compatibility with your existing infrastructure, and more. 

## Key takeaways

SIEM tools require data to be effective. As a security analyst, you will utilize SIEM tools to access events and analyze logs when you're investigating an incident. In your security career, you may even be tasked with configuring a SIEM to collect log data. It's important that you understand how data is ingested into SIEM tools because this enables you to understand where log sources come from which can help you identify the source of a security incident.

## Resources

Here are some resources if you’d like to learn more about the log ingestion process for Splunk and Chronicle:

- [Guide on getting data into Splunk](https://docs.splunk.com/Documentation/SplunkCloud/9.0.2303/Data/Howdoyouwanttoadddata)
- [Guide on data ingestion into Chronicle](https://cloud.google.com/chronicle/docs/data-ingestion-flow)

# Query for events with Splunk

- **Challenges of Searching in SIEM:** SIEM databases store vast amounts of data, including historical records that may date back years. Performing broad search queries without specific parameters can return thousands of results and slow down the search engine's response time. It's essential to make search queries as specific as possible to save time and obtain the desired results.
- **Specificity in Search Queries:** To improve search results, you should specify additional parameters such as an event ID and a date and time range. Specificity helps narrow down the search and accelerates the retrieval of relevant data. It's crucial to understand the data you're looking for and structure your query accordingly.
- **Different SIEM Search Methods:** Different SIEM tools use various search methods and query languages. For instance, Splunk utilizes its own query language called **[[Search Processing Language (SPL)]]**. SPL offers a range of search options to optimize results and retrieve the necessary data effectively.
	- **Search Example in Splunk:** An example of a raw log search in Splunk Cloud was demonstrated. The search query was designed to find events related to errors or failures in a fictional online store called Buttercup Games. The query used the index "buttercupgames" and specified search terms: "error OR fail*." The wildcard character ``"*"`` was used to account for variations in the term "fail." The search was further refined by selecting a specific time range, such as the last 30 days. The search results displayed a timeline and an events viewer, highlighting the search terms in matching events.
- **Optimizing Searches:** As a security analyst, you have the flexibility to use different commands and techniques to optimize search performance, ensuring faster and more accurate search results.

Effective querying is a fundamental skill for security analysts, enabling them to uncover security events, identify potential threats, and gain insights from SIEM databases. In the next section, you'll continue to explore how to query events, this time in Google Cloud's Chronicle.

# Query for events with Chronicle

- **[[YARA-L Language]]:** Chronicle uses the YARA-L language to define rules for event detection. YARA-L is a computer language designed for creating rules to search through ingested log data. These rules can be used to detect specific activities or behaviors, such as data exfiltration.
	- **Search Fields:** Chronicle offers various search fields to query log data, including fields like hostname, domain, IP, URL, email, username, and file hash. You can use these fields to perform different types of searches.
- **Types of search:**
	1. **[[Unified Data Model (UDM) Search]]:** The default search method in Chronicle is the UDM search, which operates on normalized data. UDM searches through the structured and formatted data, making it easier to find specific information.
		- **Example UDM Search:** An example UDM search for a failed login event was demonstrated in Chronicle. The search used structured query builder and the following query: `metadata.event_type = "USER_LOGIN" AND security_result.action = "BLOCK"`. This query is structured to search for normalized data. It specifies the event type and security action, aiming to find failed login events.
	2. **[[Raw Log Search]]:** If you can't find the data you need in normalized logs, you have the option to search raw logs. Raw logs contain unprocessed data and are used when you need to access data that hasn't been included in normalized logs or troubleshoot data ingestion issues.
- **Search Results:** The search results provide a visual representation of the data, including a timeline of events and a list of events with timestamps. Quick filters on the left allow you to further refine your search based on additional fields or values.
	- **Event Details:** Clicking on an event allows you to access the raw log associated with the event, providing more detailed information for investigation.

Performing effective searches in a SIEM tool like Chronicle is essential for security analysts to identify security events, detect anomalies, and investigate potential threats. In the upcoming activity, you'll have the opportunity to perform searches using various SIEM tools, applying the knowledge you've gained.

# Search methods with SIEM tools

So far, you’ve learned about how you can use **[[security information and event management (SIEM)]]** tools to search for security events such as failed login attempts. Remember, SIEM is an application that collects and analyzes log data to monitor critical activities in an organization. In this reading, you’ll examine how SIEM tools like Splunk and Chronicle use different search methods to find, filter, and transform search results. 

Not all organizations use the same SIEM tool to gather and centralize their security data. As a security analyst, you’ll need to be ready to learn how to use different SIEM tools. It’s important to understand the different types of searches you can perform using SIEM tools so that you can find relevant event data to support your security investigations.

## Splunk searches

As you’ve learned, Splunk has its own querying language called **[[Search Processing Language (SPL)]]**. SPL is used to search and retrieve events from indexes using Splunk’s Search & Reporting app. An SPL search can contain many different commands and arguments. For example, you can use commands to transform your search results into a chart format or filter results for specific information.

![[Pasted image 20231107211921.png]]

Here is an example of a basic SPL search that is querying an index for a failed event:

`index=main fail `

- `index=main`: This is the beginning of the search command that tells Splunk to retrieve events from an `index` named `main`. An index stores event data that's been collected and processed by Splunk.
- `fail`: This is the search term. This tells Splunk to return any event that contains the term `fail`.

Knowing how to effectively use SPL has many benefits. It helps shorten the time it takes to return search results. It also helps you obtain the exact results you need from various data sources. SPL supports many different types of searches that are beyond the scope of this reading. If you would like to learn more about SPL, explore [Splunk's Search Reference](https://docs.splunk.com/Documentation/Splunk/9.0.2/SearchReference/UnderstandingSPLsyntax).

### **Pipes**

Previously, you might have learned about how piping is used in the Linux bash shell. As a refresher, piping sends the output of one command as the input to another command.

SPL also uses the pipe character | to separate the individual commands in the search. It's also used to chain commands together so that the output of one command combines into the next command. This is useful because you can refine data in various ways to get the results you need using a single command.

Here is an example of two commands that are piped together: 

`index=main fail| chart count by host`

- `index=main fail`: This is the beginning of the search command that tells Splunk to retrieve events from an `index` named `main` for events containing the search term `fail`. 
- `|`: The pipe character separates and chains the two commands `index=main` and `chart count by host`. This means that the output of the first command `index=main` is used as the input of the second command `chart count by host`. 
- `chart count by host`: This command tells Splunk to transform the search results by creating a `chart` according to the `count` or number of events. The argument `by host` tells Splunk to list the events by host, which are the names of the devices the events come from. This command can be helpful in identifying hosts with excessive failure counts in an environment.

### **Wildcard**

A **[[wildcard]]** is a special character that can be substituted with any other character. A wildcard is usually symbolized by an asterisk character `*`. Wildcards match characters in string values. In Splunk, the wildcard that you use depends on the command that you are using the wildcard with. Wildcards are useful because they can help find events that contain data that is similar but not entirely identical. Here is an example of using a wildcard to expand the search results for a search term:

`index=main fail*`

- `index=main`: This command retrieves events from an `index` named `main`. 
- `fail*`: The wildcard after `fail` represents any character. This tells Splunk to search for all possible endings that contain the term `fail`. This expands the search results to return any event that contains the term `fail` such as “failed” or “failure”.

**Pro tip**: Double quotations are used to specify a search for an exact phrase or string. For example, if you want to only search for events that contain the exact phrase login failure, you can enclose the phrase in double quotations "login failure". This search will match only events that contain the exact phrase login failure and not other events that contain the words failure or login separately.

## Chronicle searches

In Chronicle, you can search for events using the Search field. You can also use Procedural Filtering to apply filters to a search to further refine the search results. For example, you can use Procedural Filtering to include or exclude search results that contain specific information relating to an event type or log source. There are two types of searches you can perform to find events in Chronicle, a **[[Unified Data Mode (UDM) Search]]** or a **[[Raw Log Search]]**.

![[Pasted image 20231107212118.png]]

### **Unified Data Model (UDM) Search**

The UDM Search is the default search type used in Chronicle. You can perform a UDM search by typing your search, clicking on “Search,” and selecting “UDM Search.” Through a UDM Search, Chronicle searches security data that has been ingested, parsed, and normalized. A UDM Search retrieves search results faster than a Raw Log Search because it searches through indexed and structured data that’s normalized in UDM.

![[Pasted image 20231107212128.png]]

A UDM Search retrieves events formatted in UDM and these events contain UDM fields. There are many different types of UDM fields that can be used to query for specific information from an event. Discussing all of these UDM fields is beyond the scope of this reading, but you can learn more about UDM fields by exploring [Chronicle's UDM field list](https://cloud.google.com/chronicle/docs/reference/udm-field-list). Know that all UDM events contain a set of common fields including:

- **[[Entities]]**: Entities are also known as nouns. All UDM events must contain at least one entity. This field provides additional context about a device, user, or process that’s involved in an event. For example, a UDM event that contains entity information includes the details of the origin of an event such as the hostname, the username, and IP address of the event
- **[[Event metadata]]**: This field provides a basic description of an event, including what type of event it is, timestamps, and more. 
- **[[Network metadata]]**: This field provides information about network-related events and protocol details. 
- **[[Security results]]**: This field provides the security-related outcome of events. An example of a security result can be an antivirus software detecting and quarantining a malicious file by reporting "virus detected and quarantined." 

Here’s an example of a simple UDM search that uses the event metadata field to locate events relating to user logins:

`metadata.event_type = “USER_LOGIN” `

- `metadata.event_type = “USER_LOGIN”`: This UDM field `metadata.event_type` contains information about the event type. This includes information like timestamp, network connection, user authentication, and more. Here, the event type specifies `USER_LOGIN`, which searches for events relating to authentication. 

Using just the metadata fields, you can quickly start searching for events. As you continue practicing searching in Chronicle using UDM Search, you will encounter more fields. Try using these fields to form specific searches to locate different events.

### **Raw Log Search** 

If you can't find the information you are searching for through the normalized data, using a Raw Log Search will search through the raw, unparsed logs. You can perform a Raw Log Search by typing your search, clicking on “Search,” and selecting “Raw Log Search.” Because it is searching through raw logs, it takes longer than a structured search. In the Search field, you can perform a Raw Log Search by specifying information like usernames, filenames, hashes, and more. Chronicle will retrieve events that are associated with the search.

**Pro tip**: Raw Log Search supports the use of regular expressions, which can help you narrow down a search to match on specific patterns.

## Key takeaways

SIEM tools like Splunk and Chronicle have their own methods for searching and retrieving event data. As a security analyst, it's important to understand how to leverage these tools to quickly and efficiently find the information you need. This will allow you to explore data in ways that support detecting threats, as well as rapidly responding to security incidents. 

## Resources for more information

Here are some resources should you like to learn more about searching for events with Splunk and Chronicle:

- [Splunk’s Search Manual](https://docs.splunk.com/Documentation/Splunk/9.0.1/Search/GetstartedwithSearch) on how to use the Splunk search processing language (SPL)
- [Chronicle's quickstart guide](https://cloud.google.com/chronicle/docs/review-security-alert) on the different types of searches